#!/usr/bin/env python3
import os
import sys
import argparse
import gzip
import json
from statistics import mean, median, stdev

LOG_DIR = "./logs"


def parse_log(file_path):
	"""
	Parse a log file to extract FPS, Draw time, and Update time values per resolution.
	"""
	with gzip.open(file_path, "rt") as file:
		log_data = json.load(file)
	parsed_data = {}
	for entry in log_data:
		parsed_data[entry["resolution"]] = {
			"fps": entry["fps"],
			"draw_times": entry["draw_time"],
			"update_times": entry["update_time"],
		}
	return parsed_data


def calc_metrics(data):
	"""
	Calculate min, max, mean, median, and standard deviation for a list of data.
	"""
	return {
		"min": min(data),
		"max": max(data),
		"mean": mean(data),
		"median": median(data),
		"stdev": stdev(data),
	}


def calc_stats(file_paths):
	"""
	Calculate statistics (min, max, mean, median, stdev) for FPS, Draw time, and Update time.
	"""
	raw_data = {}
	for file_path in file_paths:
		try:
			log_data = parse_log(file_path)
		except Exception as e:
			print(f"Error: Failed to parse log file {file_path}: {e}", file=sys.stderr)
			continue
		for res, metrics in log_data.items():
			if res not in raw_data:
				raw_data[res] = {"fps": [], "draw_times": [], "update_times": []}
			raw_data[res]["fps"].extend(metrics["fps"])
			raw_data[res]["draw_times"].extend(metrics["draw_times"])
			raw_data[res]["update_times"].extend(metrics["update_times"])
	stats = {}
	for res, metrics in raw_data.items():
		stats[res] = {
			"fps": calc_metrics(metrics["fps"]),
			"draw_times": calc_metrics(metrics["draw_times"]),
			"update_times": calc_metrics(metrics["update_times"]),
		}
	return stats


def print_stats(stats):
	"""
	Print statistics in a tabular format.
	"""
	print(" " + "-" * 95, file=sys.stdout)
	print(f"| {'Res':<10} | {'Metric':<16} | {'Min':<10} | {'Max':<10} | {'Mean':<10} | {'Median':<10} | {'Std Dev':<10}|", file=sys.stdout)
	print("|" + "-" * 95 + "|", file=sys.stdout)
	for res, metrics in stats.items():
		print(f"|            | {'FPS':<16} | {metrics['fps']['min']:<10.2f} | {metrics['fps']['max']:<10.2f} | {metrics['fps']['mean']:<10.2f} | {metrics['fps']['median']:<10.2f} | {metrics['fps']['stdev']:<10.2f}|", file=sys.stdout)
		print(f"| {res:<10} | {'Draw time (ns)':<16} | {metrics['draw_times']['min']:<10.2f} | {metrics['draw_times']['max']:<10.2f} | {metrics['draw_times']['mean']:<10.2f} | {metrics['draw_times']['median']:<10.2f} | {metrics['draw_times']['stdev']:<10.2f}|", file=sys.stdout)
		print(f"|            | {'Update time (ns)':<16} | {metrics['update_times']['min']:<10.2f} | {metrics['update_times']['max']:<10.2f} | {metrics['update_times']['mean']:<10.2f} | {metrics['update_times']['median']:<10.2f} | {metrics['update_times']['stdev']:<10.2f}|", file=sys.stdout)
		print(" " + "-" * 95, file=sys.stdout)


# Parse arguments
parser = argparse.ArgumentParser(description="Process log files to calculate statistics.")
parser.add_argument("-c", "--compare", action="store_true", help="Compare two versions of logs.")
parser.add_argument("-m", "--max-logs", type=int, default=10, help="Maximum number of log files to process.")
args = parser.parse_args()

# Prepare log files
if args.compare:
	v1_files = [os.path.join(LOG_DIR, f"results.json.log.{i}.gz") for i in range(args.max_logs // 2)]
	v2_files = [os.path.join(LOG_DIR, f"results.json.log.{i}.gz") for i in range(args.max_logs // 2, args.max_logs - 1)]
	v1_files[0] = os.path.join(LOG_DIR, "results.json.log.gz")
	print("First version:")
	print_stats(calc_stats(v1_files))
	print("\nSecond version:")
	print_stats(calc_stats(v2_files))
	sys.exit(0)

if args.max_logs < 1:
	print("Error: Maximum number of logs must be at least 1.", file=sys.stderr)
	sys.exit(1)
if not os.path.exists(os.path.join(LOG_DIR, f"results.json.log.{args.max_logs - 1}.gz")):
	print(f"Error: Not enough logs found in {LOG_DIR}.", file=sys.stderr)
	sys.exit(1)

all_files = [os.path.join(LOG_DIR, f"results.json.log.{i}.gz") for i in range(args.max_logs)]
all_files[0] = os.path.join(LOG_DIR, "results.json.log.gz")
print_stats(calc_stats(all_files))
